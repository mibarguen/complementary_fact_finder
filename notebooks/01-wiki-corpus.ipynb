{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mateoibarguen/Desktop/CSC 482/complementary_fact_finder\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import WikiCorpus, MmCorpus, Dictionary\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import os\n",
    "import random\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "1) Load Wikipedia Corpus. [(Title: Sentence), ... ]\n",
    "2) Tokenize each sentence in Wikipedia corpus.\n",
    "3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load WikiCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sent):\n",
    "    return re.sub(r\"\\n|\\'\", '', sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, token_min_len, token_max_len, lower):\n",
    "    # override original method in wikicorpus.py\n",
    "    return [token for token in sent_tokenize(text)\n",
    "            if len(token) >= 20 and not token.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sdlfkjds sdlkjf. sdlfkj sdfsd sdf.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = 'sdlfkjds sdlkjf. sdlfkj sdfsd sdf.'\n",
    "re.sub(r'[^\\w\\s.]', '', ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process InputQueue-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/gensim/utils.py\", line 1218, in run\n",
      "    wrapped_chunk = [list(chunk)]\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/gensim/corpora/wikicorpus.py\", line 676, in <genexpr>\n",
      "    ((text, self.lemmatize, title, pageid, tokenization_params)\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/gensim/corpora/wikicorpus.py\", line 424, in extract_pages\n",
      "    for elem in elems:\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/gensim/corpora/wikicorpus.py\", line 409, in <genexpr>\n",
      "    elems = (elem for _, elem in iterparse(f, events=(\"end\",)))\n",
      "  File \"/anaconda3/lib/python3.7/xml/etree/ElementTree.py\", line 1224, in iterator\n",
      "    data = source.read(16 * 1024)\n",
      "  File \"/anaconda3/lib/python3.7/_compression.py\", line 103, in read\n",
      "    data = self._decompressor.decompress(rawblock, size)\n",
      "  File \"/anaconda3/lib/python3.7/bz2.py\", line 178, in read\n",
      "    return self._buffer.read(size)\n",
      "  File \"/anaconda3/lib/python3.7/_compression.py\", line 68, in readinto\n",
      "    data = self.read(len(byte_view))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "wiki = WikiCorpus('data/simplewiki-latest-pages-articles.xml.bz2', tokenizer_func=tokenize)\n",
    "wiki.metadata = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki.metadata = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_text = wiki.get_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_abstract(sents):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_text = wiki.get_texts()\n",
    "sents = []\n",
    "length = 100\n",
    "i = 0\n",
    "for t in wiki_text:\n",
    "    title = t[1][1]\n",
    "    sents_topic = [(title, clean_sentence(s)) for s in t[0] if s[0] != '*']\n",
    "    sents.extend(sents_topic)\n",
    "    i += 1\n",
    "    if i > length:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize WikiCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_tokens = [word_tokenize(s[1]) for s in sents]\n",
    "# wiki_dict = Dictionary(wiki_tokens)\n",
    "# wiki_corpus = [wiki_dict.doc2bow(t) for t in wiki_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LDA on WikiCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(wiki_corpus, num_topics=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LSI on WikiCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(wiki_corpus, id2word=wiki_dict, num_topics=2)\n",
    "index = MatrixSimilarity(lsi[wiki_corpus])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_doc(doc, lsi, index, wiki_dict):\n",
    "    sim_df = pd.DataFrame()\n",
    "    doc_tokens = word_tokenize(doc)\n",
    "    doc_vec_bow = wiki_dict.doc2bow(doc_tokens)\n",
    "    vec_lsi = lsi[doc_vec_bow]\n",
    "    sims = index[vec_lsi]\n",
    "    sim_df['sents'] = wiki_tokens\n",
    "    sim_df['sim'] = sims\n",
    "    return sim_df.sort_values(by='sim', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sents</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>[====, Additive, inverse, property, ====The, a...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7540</th>\n",
       "      <td>[It, is, always, in, the, middle, of, winter, ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5896</th>\n",
       "      <td>[Bing, is, known, for, the, different, images,...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>[Tobacco, is, made, into, cigars, by, hand, .]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>[Observing, the, Sun, can, help, us, understan...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>[Its, infant, death, rate, is, lower, than, so...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4021</th>\n",
       "      <td>[Hydrogen, is, the, chemical, element, with, t...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6579</th>\n",
       "      <td>[This, is, an, irrational, number, .]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6758</th>\n",
       "      <td>[Pronouns, have, commonly, been, considered, a...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6973</th>\n",
       "      <td>[There, are, also, many, smaller, islands, .]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>[Religions, have, different, beliefs, about, t...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7157</th>\n",
       "      <td>[Some, philosophers, are, from, the, Middle, A...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>[Small, churches, are, called, chapels, .]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>[Some, churches, may, now, have, replaced, the...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>[Over, the, triforium, is, the, clerestory, wh...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>[If, there, is, a, recess, in, the, wall, it, ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>[Some, count, this, daily, adjustment, as, com...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>[The, carpel, is, the, female, part, of, the, ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>[===, Rituals, surrounding, death, ===Every, e...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>[People, live, in, cities, because, it, is, ea...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>[==, Early, life, and, family, ==Alan, Turing,...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>[Every, year, the, government, chooses, a, big...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>[Because, of, this, ,, people, sometimes, call...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>[===, Eel-like, ===The, long, ,, ribbon-like, ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3108</th>\n",
       "      <td>[Casual, groups, are, called, shoals, .]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>[But, both, Newton, and, Leibniz, were, the, f...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8080</th>\n",
       "      <td>[Underground, rivers, form, in, places, where,...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>[People, may, buy, food, and, take, it, home, ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2679</th>\n",
       "      <td>[There, are, three, ways, plates, can, come, t...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>[Cuba, is, warm, all, year, .]</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>[266, (, 1–2, ), :, 5–43, .]</td>\n",
       "      <td>0.258617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>[List, of, regions, Danish, name, English, nam...</td>\n",
       "      <td>0.256588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>[==Related, pages==*Political, economy*Constit...</td>\n",
       "      <td>0.254561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>[London, working, class, version, :, I, aint, ...</td>\n",
       "      <td>0.248253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4670</th>\n",
       "      <td>[Astrological, signs, for, July, are, Cancer, ...</td>\n",
       "      <td>0.244584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>[It, came, from, meta, (, beyond, ), and, pher...</td>\n",
       "      <td>0.244198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6597</th>\n",
       "      <td>[For, example, ,, 5i, ×, 3i, =, (, 5, ×, 3, ),...</td>\n",
       "      <td>0.243326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>[An, example, would, be, reacting, hydrochlori...</td>\n",
       "      <td>0.240322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>[Thorlaks, Day, (, Iceland, ), *, December, 23...</td>\n",
       "      <td>0.237904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>[So, for, example, if, a, beryllium, atom, (, ...</td>\n",
       "      <td>0.232773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6475</th>\n",
       "      <td>[==Taxonomy==The, evolutionary, relationships,...</td>\n",
       "      <td>0.232438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3707</th>\n",
       "      <td>[==, References, ====, Other, websites, ==*, *...</td>\n",
       "      <td>0.224283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>[Eleven, hours, after, Sydney, ,, Edinburgh, i...</td>\n",
       "      <td>0.220990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713</th>\n",
       "      <td>[John, is, (, jon, ), but, can, also, be, (, n...</td>\n",
       "      <td>0.220562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8320</th>\n",
       "      <td>[Radio, waves, (, 1887, ), Radio, quickly, bec...</td>\n",
       "      <td>0.212903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>[For, example, ,, (, 7, +, 5i, ), −, (, 3, +, ...</td>\n",
       "      <td>0.192253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610</th>\n",
       "      <td>[For, example, ,, (, 2, +, 3i, ), +, (, 3, +, ...</td>\n",
       "      <td>0.191259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>[==, Related, pages, ==*, List, of, planets*, ...</td>\n",
       "      <td>0.190628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>[==, Military, ==Nuclear, aircraft, carrier, C...</td>\n",
       "      <td>0.169318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6614</th>\n",
       "      <td>[For, example, ,, (, 4, +, 5i, ), ×, (, 3, +, ...</td>\n",
       "      <td>0.136350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>[Macronutrients, :, *, N, =, Nitrogen, (, Carb...</td>\n",
       "      <td>0.107857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>[==, Other, websites, ==*, *, *]</td>\n",
       "      <td>0.083430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>[==Gallery==File, :, Ursus, maritinus.jpg|Pola...</td>\n",
       "      <td>0.082137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>[==, References, ====, Other, websites, ==*, G...</td>\n",
       "      <td>0.071151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>[(, Do, people, have, free, will, ?, )]</td>\n",
       "      <td>0.066261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>[Province, Dutch, name, French, name, Capital,...</td>\n",
       "      <td>0.040645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>[==Largest, Computer, Companies==, Company, na...</td>\n",
       "      <td>0.034042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9049</th>\n",
       "      <td>[==, Famous, people, who, were, slaves, ==*, A...</td>\n",
       "      <td>0.026724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>[==, Physicists, =====Prominent, theoretical, ...</td>\n",
       "      <td>0.020759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7659</th>\n",
       "      <td>[==Related, pages==*, Spore*, Seed*, Germinati...</td>\n",
       "      <td>-0.032065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9110 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sents       sim\n",
       "670   [====, Additive, inverse, property, ====The, a...  1.000000\n",
       "7540  [It, is, always, in, the, middle, of, winter, ...  1.000000\n",
       "5896  [Bing, is, known, for, the, different, images,...  1.000000\n",
       "2233     [Tobacco, is, made, into, cigars, by, hand, .]  1.000000\n",
       "963   [Observing, the, Sun, can, help, us, understan...  1.000000\n",
       "2217  [Its, infant, death, rate, is, lower, than, so...  1.000000\n",
       "4021  [Hydrogen, is, the, chemical, element, with, t...  1.000000\n",
       "6579              [This, is, an, irrational, number, .]  1.000000\n",
       "6758  [Pronouns, have, commonly, been, considered, a...  1.000000\n",
       "6973      [There, are, also, many, smaller, islands, .]  1.000000\n",
       "2517  [Religions, have, different, beliefs, about, t...  1.000000\n",
       "7157  [Some, philosophers, are, from, the, Middle, A...  1.000000\n",
       "1856         [Small, churches, are, called, chapels, .]  1.000000\n",
       "1887  [Some, churches, may, now, have, replaced, the...  1.000000\n",
       "1893  [Over, the, triforium, is, the, clerestory, wh...  1.000000\n",
       "1910  [If, there, is, a, recess, in, the, wall, it, ...  1.000000\n",
       "1550  [Some, count, this, daily, adjustment, as, com...  1.000000\n",
       "7612  [The, carpel, is, the, female, part, of, the, ...  1.000000\n",
       "2557  [===, Rituals, surrounding, death, ===Every, e...  1.000000\n",
       "1949  [People, live, in, cities, because, it, is, ea...  1.000000\n",
       "132   [==, Early, life, and, family, ==Alan, Turing,...  1.000000\n",
       "416   [Every, year, the, government, chooses, a, big...  1.000000\n",
       "2600  [Because, of, this, ,, people, sometimes, call...  1.000000\n",
       "3120  [===, Eel-like, ===The, long, ,, ribbon-like, ...  1.000000\n",
       "3108           [Casual, groups, are, called, shoals, .]  1.000000\n",
       "2032  [But, both, Newton, and, Leibniz, were, the, f...  1.000000\n",
       "8080  [Underground, rivers, form, in, places, where,...  1.000000\n",
       "3007  [People, may, buy, food, and, take, it, home, ...  1.000000\n",
       "2679  [There, are, three, ways, plates, can, come, t...  1.000000\n",
       "2102                     [Cuba, is, warm, all, year, .]  1.000000\n",
       "...                                                 ...       ...\n",
       "563                        [266, (, 1–2, ), :, 5–43, .]  0.258617\n",
       "2425  [List, of, regions, Danish, name, English, nam...  0.256588\n",
       "2809  [==Related, pages==*Political, economy*Constit...  0.254561\n",
       "3567  [London, working, class, version, :, I, aint, ...  0.248253\n",
       "4670  [Astrological, signs, for, July, are, Cancer, ...  0.244584\n",
       "5992  [It, came, from, meta, (, beyond, ), and, pher...  0.244198\n",
       "6597  [For, example, ,, 5i, ×, 3i, =, (, 5, ×, 3, ),...  0.243326\n",
       "1479  [An, example, would, be, reacting, hydrochlori...  0.240322\n",
       "2284  [Thorlaks, Day, (, Iceland, ), *, December, 23...  0.237904\n",
       "822   [So, for, example, if, a, beryllium, atom, (, ...  0.232773\n",
       "6475  [==Taxonomy==The, evolutionary, relationships,...  0.232438\n",
       "3707  [==, References, ====, Other, websites, ==*, *...  0.224283\n",
       "2283  [Eleven, hours, after, Sydney, ,, Edinburgh, i...  0.220990\n",
       "6713  [John, is, (, jon, ), but, can, also, be, (, n...  0.220562\n",
       "8320  [Radio, waves, (, 1887, ), Radio, quickly, bec...  0.212903\n",
       "6611  [For, example, ,, (, 7, +, 5i, ), −, (, 3, +, ...  0.192253\n",
       "6610  [For, example, ,, (, 2, +, 3i, ), +, (, 3, +, ...  0.191259\n",
       "4922  [==, Related, pages, ==*, List, of, planets*, ...  0.190628\n",
       "3239  [==, Military, ==Nuclear, aircraft, carrier, C...  0.169318\n",
       "6614  [For, example, ,, (, 4, +, 5i, ), ×, (, 3, +, ...  0.136350\n",
       "7595  [Macronutrients, :, *, N, =, Nitrogen, (, Carb...  0.107857\n",
       "564                    [==, Other, websites, ==*, *, *]  0.083430\n",
       "6491  [==Gallery==File, :, Ursus, maritinus.jpg|Pola...  0.082137\n",
       "853   [==, References, ====, Other, websites, ==*, G...  0.071151\n",
       "7177            [(, Do, people, have, free, will, ?, )]  0.066261\n",
       "1295  [Province, Dutch, name, French, name, Capital,...  0.040645\n",
       "1677  [==Largest, Computer, Companies==, Company, na...  0.034042\n",
       "9049  [==, Famous, people, who, were, slaves, ==*, A...  0.026724\n",
       "7347  [==, Physicists, =====Prominent, theoretical, ...  0.020759\n",
       "7659  [==Related, pages==*, Spore*, Seed*, Germinati... -0.032065\n",
       "\n",
       "[9110 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_doc('April is my favorite month.', lsi, index, wiki_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(common_texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in common_texts]\n",
    "\n",
    "# Train the model on the corpus.\n",
    "# lda = LdaModel(common_corpus, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in wiki.sample_texts(50, length=10000):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "common_dictionary = Dictionary(common_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer\n"
     ]
    }
   ],
   "source": [
    "print(common_dictionary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stopwords])\n",
    "    normalized = \" \".join(lemma.lemmatize(word,'v') for word in stop_free.split())\n",
    "    x = normalized.split()\n",
    "    y = [s for s in x if len(s) > 2]\n",
    "    return y\n",
    "\n",
    "def get_related_documents(term, top, corpus):\n",
    "    clean_docs = [clean_doc(doc) for doc in corpus]\n",
    "    related_docid = []\n",
    "    test_term = [ldamodel.id2word.doc2bow(doc) for doc in clean_docs]\n",
    "    doc_topics = ldamodel.get_document_topics(test_term, minimum_probability=0.20)\n",
    "    term_topics =  ldamodel.get_term_topics(term, minimum_probability=0.000001)\n",
    "    for k,topics in enumerate(doc_topics):\n",
    "        if topics:\n",
    "            topics.sort(key = itemgetter(1), reverse=True)\n",
    "            if topics[0][0] == term_topics[0][0]:\n",
    "                related_docid.append((k,topics[0][1]))\n",
    " \n",
    "    related_docid.sort(key = itemgetter(1), reverse=True)\n",
    "    for j,doc_id in enumerate(related_docid):\n",
    "        print (doc_id[1],\"\\n\\n\",docs_test[doc_id[0]])\n",
    "        if j == (top-1):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(common_texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in common_texts]\n",
    "\n",
    "# Train the model on the corpus.\n",
    "lda = LdaModel(common_corpus, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.ldamodel.LdaModel at 0x108c6d860>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_texts = [['computer', 'time', 'graph'], ['survey', 'response', 'eps'],['human', 'system', 'computer']]\n",
    "other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]\n",
    "unseen_doc = other_corpus[0]\n",
    "vector = lda[unseen_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "from gensim.similarities import MatrixSimilarity\n",
    "# https://radimrehurek.com/gensim/tut3.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi = models.LsiModel(common_corpus, id2word=common_dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = MatrixSimilarity(lsi[common_corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"Human computer interface. How are you?\"\n",
    "vec_bow = common_dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.998093), (1, 0.93748635), (2, 0.9984453), (3, 0.9865886), (4, 0.90755945), (5, -0.12416792), (6, -0.10639259), (7, -0.09879464), (8, 0.050041765)]\n"
     ]
    }
   ],
   "source": [
    "sims = index[vec_lsi]\n",
    "print(list(enumerate(sims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
